pref: [[3 Theoretische Grundlagen]]
[[1#Problem Flexibilit√§t und Agilit√§t k√∂nnte duirch EDA gel√∂st werden werden sie aber nicht]]
[[1 üöß Projects/üéì Bachelorarbeit/Literatur/Bruns, Dunkel -¬†Event-Driven Architecture.md]]
[[1#Kein CEP im BPM Umfeld]]
[[1#Gr√ºnde f√ºr die fehlende Verbreitung von EDA]]
[[4 üóÑÔ∏è Archive/üéì Bachelorarbeit 1/Literatur/Bruns, Dunkel - Event-Driven Architecture]]

# Problemidentifizierung und Motivaton + L√∂sungsziele definieren
Zun√§chst wird das Problem, welches diese Arbeit behandelt wird identifiziert sowie die daraus resultierende Motivation n√§her el√§utert. Daraus ergeben sich Kandiaten f√ºr die Design Principles (DP) (vgl. 3. Forschungsmethode) welche sp√§ter genutzt werden um wissen √ºber das Artefakt zu erfassen. 

F√ºr eine einheitliche Definition der DP wird der ISO Standard 1926 verwendet.

## Problemidentifizierunng
Konventionelle betriebliche IT-Systeme bieten h√§ufig nicht die erforderliche Flexibilit√§t, um die fachliche Agilit√§t abzubilden. Erschwerend kommt hinzu, dass die internen und externen Anforderung an Agilit√§t stetig wachsen, unter anderem durch erweitere technische M√∂glichkeiten oder ver√§ndertes Kundenverhalten [@brunsEventDrivenArchitecture2010, p.3] [@averyJourneyEventDriven2019]. Vor dem Hintergrund der Digitalisierung und den sich daraus resultiertende Ver√§nderung von Unternehmenprozessen stellen sich besondere Herausforderung an die Flexibilit√§t von Unternehmen (Quelle). 

> **DP2: Anpassbarkeit** Ist das Artefakt in der Lage sich an Ver√§nderungen im Umfeld anzupassen? 

H√§ufig sind starre Implementierungen von Gesch√§ftsprozessen das Problem. Da tratdionionell de Fokus auf Zust√§nden und nocht auf Ereignissen leigt, sind Ver√§nderungen dieser Prozesse mit gro√üen Aufwand und Risiko Verbunden (Klotz). Bei dieser Sichtweise sind Daten und Prozesseschritte eng miteineander gekoppelt, man spricht auch von monolithischen Prozessdesign. 

> **DP3: Ver√§nderbarkeit** Das Artefakt kann ver√§ndert und modifiziert werden.

> **DP1: Austauschbarkeit** Die Komponenten des Artwefakts sind austauschbar.

L√∂sungsans√§tze bieten Event-Driven Architecture (EDA), als Architekturstil und Complex Event Processing (CEP) als Softwaretechnologie. Sie repr√§sentieren einen neuen Stil von betrieblicher Softwarearchitektur, bei dem Ereignisse in das Zentrum der Softwarearchitektur r√ºcken. Die resultierenden ereignisgesteuerten Anwendungssysteme erm√∂glichen eine realit√§tsnahe Abbildung der ereignisgesteuerten Gesch√§ftsprozesses eines Unternehmens [@averyJourneyEventDriven2019, p. 4-5].

Ereignisgetrieben Architekturen haben sich in den letzen Jahren gro√üer Beliebtheit erfreut. Dieser Architekturstil fokussiert auf die Ereignisse, die Ver√§nderungen der vorhandenen Daten bewirken (anstelle der Zust√§nde). Auf diese Weise lassen sich sehr gro√üe und vor allem skalierbare Integrationen erstellen, zum Beispiel auf Basis des ‚ÄúPublish-and-Subscribe‚Äù-Architekturkonzepts (Klotz).

##### Teilbereich BPM: Kein CEP im BPM Umfeld
*Noch auf Grundlagenteil: Anwenudng EDA vezhiehen*

EDA und insbesondere Event-Driven Service-Oriented Architecture (ED-SOA) erfahren in den letzten Jahren wachsende Aufmerksamkeit in verschiedensten Bereichen [@hamzahEXPLORATORYSTUDYINVESTIGATING2020, p.273-304] [@shaheenResearchSOAIT2019, p.149-154]. Des Weiteren bietet zunehmende Verbreitung von CEP zahlreiche neue M√∂glichkeiten im Business Process Management (BPM) [@lundbergLeverageComplexEvent2006, p.55-65].

Trotz der Verbeitung von ereignisgetrieben Architekturen allgemein ist zu erkennen, dass Anwendungen im ber des Gesch√§fprozessmanagement eher selten anzutreffen sind (Klotz).

Dies scheint verwunderlich, denn gerade diese mangelnde Flexibilit√§t und Agilit√§t k√∂nnte durch den Einsatz von CEP gel√∂st werden. Grund f√ºr die Etablierung von rigider und unflexibler Software ist die sukzessive fl√§chendeckende Einf√ºhrung solcher Systeme seit Anfang der 90er Jahre [@bungardEinfuehrungUnternehmensweiterStandardSoftwarePakete2005, p.14-21]. In der Vergangenheit wurden feste Unternehmensprozesse in Software ‚Äûgepresst‚Äú [@bayerAnwenderBrauchenMehr2016]. Um sich von diesen technischen Schulden zu l√∂sen ist die Modernisierung von konventionellen betrieblichen Systemen zu SOA basierten Systemen zu einem Mainstream-Trend geworden [@abdellatifStatePracticeService2018, 643-650]

Alle Aktivit√§ten besitzen ein aus√∂sendes Ereignis und k√∂nnen selbst wiederum eine Reihe von Ereignissen ausl√∂sen. Auf diese Weise k√∂nnen Prozesse sher einfach und risikoarm erweitert und in einer verteilten Umgebung bearbeitet werden. (Klotz) 

Ziel dieser Arbeit ist es daher, dem urspr√ºnglichen Konzept der Ereignisgestuerten Prozesskette n(EPK) auf der Basis einer modernen Architektur wieder neues Leben einzuhauchen. Hierf√ºr soll in verschienden Stufen ein Protoyp konzipiert und implementert werden, welche demonstiert, dass Gesch√§ftsprozesse auf der Basis einer leisungsf√§higen ereignisgetrieben Plattform wie Apache Kafka robust und sicher implementiert und orchesriert werden k√∂nnen (Klotz).

**DP4: Tauglichkeit** Erf√ºllt das Artefkat adequat alle funktionalen Anfoderungen? 

##### Fehlerhafte Ereignisse erzeugen hohe Kosten
Bei der Anwendung von ereignisgesteuerten Pub-Sub Systemen kommt es nicht selnten vor, dass Millionen Ereignisse pro Sekunde verarbeitet werden. Sollte ein Fehler w√§hrend der Laufzeit passieren, wird dieser oft zu sp√§t entdeckt und es wurden bereits viele falsch Ereignisse verarbitet. Dies kann Immenze kosten verursachen. Deshalb soll eine Architektur definiert werden, welche  weiterhin auf dem *Publish-Subscribe-Pattern* basiert, allerdings zur Laufzeit Ereignisse pr√ºft und validiert umd solche Fehler zu vermeiden.
Die Anwendung soll sich auf die Implementierung von Gesch√§fprozessen in eine IT-Infrastruktur erm√∂glichen.

> **DP5: Fehlertoleranz** Ist das Artefakt in der Lage ein ein Level an Performanz zu halten auch wenn Fehler oder Verst√∂√üe gegen Regeln vorliegen? 

## (Gr√ºnde f√ºr die fehlende Verbreitung von EDA)
Die Gr√ºnde f√ºr die fehlende Verbreitung sind wenig erforscht, Bruns und Dunkel (2010) nennen mehre Gr√ºnde, von denen die zwei trotz des Alters auch heute noch beobachtbar sind. Der erste m√∂glichen Grund  sind unvollst√§ndige sowie fehlende Standards. Dazu geh√∂ren vor allem fehlende technische Standards f√ºr wichtige EDA-Komponenten wie eine Event Processing Language (EPL) zur Beschreibung von Ereignis -typen und -regeln. Als weiterer Grund wird die Abwesenheit einer etablierten Entwicklungsmethodik genannt. Es existieren nur wenige ausgereifte Methodiken f√ºr die Entwicklung von ereignisgesteuerten Anwendungssystemen. Insbesondere Richtlinien, Entwurfsmuster, Best-Practise-Beispiele, wiederverwendbare Komponenten oder Vorgehensmodelle f√ºr EDA existieren oftmals nur in rudiment√§rer Form [@brunsEventDrivenArchitecture2010, p234-235]. 

> **DP4: Interoperabilit√§t** Das Artefakt ist in der Lage mit anderen System zu inteagieren und nutzt g√§nige Standards.

Dar√ºber hinaus ist die Qualit√§t der angewendeten Systeme von Bedeutung. Unternehmen mit ereignisgesteuerten Architekturen verarbeiten Millionen von Ereignissen pro Sekunde [@churchwardExtremeAgilityTry2008] hier kann bereits ein kleiner Fehler in der Architektur gro√üen Schaden anrichten.

## Herausforderungen im Umgang mit Ereignissen 
Die Menge an Ereignissen steig kontinuierlich an. Folgende Faktoren tragen im wesentlichen dazu bei, dass Unternehmen mit einem steig wachsenen Strom von Ereignissen umgehen m√ºssen:  [@brunsEventDrivenArchitecture2009, p.29-30]

1. **Fachliche Komplexit√§t**
   Gesch√§ftsprozesse innerhalb eines Unternehmens vernetzen heutzutage unterschiedliche Abteilungen, Standorte und Fertigungst√§tten im In- und Ausland. Eine fortschreitende Arbeitsteilung zwischen Unternehmen f√ºhrt zu einer engen, unternehmens√ºbergreifenden Kopplung der Prozesse von Produzenten und Zulieferen entlang der Fertigungskette. 
2. **Technische Komplexit√§t**
   Die meisten gr√∂√üeren Unternehmen besitzen eine komplexte und heterogene IT-Infrastruktur, welche historisch gewachsen ist. Es werden eine Vielzahl an Programmiersprachen, Technologien, Datenformaten und Schnittstellen verwendet.
3. **Kommunikation mit der physikalischen Umwelt**
   Sensorennetzwerke √ºbermitteln Messdaten aus der physikalischen Welt und stellen hierdurch eine Verbindung zwischen den Unternehmenswendungen und der Au√üenwelt dar. 
4. **Datenmenge**	 
   Unternehmen m√ºssen die zunehmende Anzahl an ereignissen systematisch identifizen und zeit- sowie ortsabh√§nig bereitstellen. Eine Herausvorderungen ist es dabei die anwachsende Menge an Ereignisedaten in die laufenden operativen Gesch√§ftsprozesse zu integrieren. 
   
## Begr√ºndung f√ºr nicht gew√§hlte Desing Principles (ISO)
*TODO*

# 2 Konzeption und Entwicklung 
## Beschreibung des Prototyps
Durch den Validator erreicht die Architektur eine Struktur welche mit der Mediator Topolgie vergleichbar ist. Der entscheidente Vorteil dieses Architekturansatzes ist, dass Fehler welche zur Laufzeit direkt erkannt und somit nicht wiederholt werden k√∂nnen. Bei der Anwendung von Publish-Subscribe Systemen im Unternehmenskontext werden nicht selten Millionen von Ereignissen in der Sekunde verarbeitet. Einfache Fehler k√∂nnen sich somit in kurzer Zeit oft wiederholen. Durch diese Architekturprinzup werden Ereignisse zur Laufzeit gepr√ºft und validiert und die Wiederholdung von Fehler wird somit ausgeschlossen  

Im folgenden wird eine ereignisgesteurte Architektur entwickelt, welche anschlie√üend prototypisch implementiert werden soll. 

F√ºr die Entwicklung des Konzept wurde verschiedene Ans√§tze gew√§hlt welche von Bruhns und Dunkel (2010) sowie Vogel (2009) n√§her ausgef√ºhrt werden. 

**Komponenten-Orientierung:** Komponente sind wiederverwendbar und in sich geschlossene Bausteiner einer Architektur. Komponentenorientierung etnstand aus der Problematik, dass Objekte in der objektorientierten Programmierung zar das Modularit√§tsprinzip umsetzten, aber als wiederverwendbar Einheiten oft zu klein sind [@vogelSoftwareArchitekturGrundlagenKonzepte2009, p.161-162]. 

> Eine Komponente ist eine Kompositionseinheit mit vertraglich spezifizierten Schnittstellen, die nur explizite Abh√§ngigkeiten zu ihrem Kontext hat. Eine Software-Komponente kann unabh√§ngig einge-setzt werden und sie kann durch Dritte komponiert werden. 

**Meta-Architekturen und Reflection:** Durch Meta-Programmierung erreichen Software-Systeme durch eine zus√§tzliche Abstratkionsebene mehr Flexibilit√§t und Kontrollle. In der Regel wird zwischen dem Programm als ausf√ºhrbare Answeisungen und den Daten, mit dem das Programm arbeitet, unterschieden. 
In der Regeln werden w√§hrend der Laufzeit nur die Daten ge√§nderund und nicht das Programm selbst. Das Paradigma der Meta-Programmierung (auch Reflexion oder Introspektion genannt) macht dies allerdings m√∂glich und erlaubt dem Programm den Zugriff auf sich selbst. 

Damit hat das Programm zur Laufzeit informationen √ºber Typinformationen, KLassen, Variablen und Methoden sowie die Vererbungshiearchie. Mit Reflexion ist es m√∂glich, dynamisch Methoden aufzurufen, Klassen zu instanzieieren. [@vogelSoftwareArchitekturGrundlagenKonzepte2009, p.164]. 

Folgende funktionale Anfoderungen an das Artefakt wurden anhand der Problemdefinition sowie anhand √úbelegungen zur Architektur definiert.
Sie werden in nat√ºrlicher Sprache nach den Regeln von Rupp et al. (2009) formuliert: [@ruppRequirementsEngineeringUndManagement2001a, p.228 ff]

**A1 Beschreibungssprache:** Zur Setup-Phase muss das System dem Anwender die M√∂glichkeit bieten, ereignisgesteuerte Gesch√§ftsprozesse mit einer Beschreibungsssprache zu modellieren.

**A2 Syntaxpr√ºfung:** Zur Setup-Phase muss das System Syntaxfehler der Beschreibungssprache erkennen und dem Anwender zur√ºck melden.

**A3 Erstellung von Kafka Komponenten:** Zur Laufzeit muss das System anhand Bescheibungssprache die Kafka Komponenten Producer, Consumer, Topics und Events erzeugen.

**A4 Validierung:** Zur Laufzeit muss das Sytem eintreffende Ereignisse validieren und diese entsprechend in outbound-Topics oder error-Topics speichern.

**A5 √Ñnderungen zur Laufzeit:** Zur Laufzeit soll das System in der Lage sein √Ñnderungen der Beschreibungssprache zu verarbeiten und die Kafka Komponenten aus Anfoderungen A2 anzupassen.

## Modul 1: Notation
Ziel des Moduls ist die Defnition einer Domain Specific Langage (DSL) in Form einer Beschreibungssprache f√ºr Gesch√§ftsprozesse. Ziel der Beschreibungsssprache ist es ereignisgesteuerte Prozessabl√§ufte zu modellieren. Diese Beschreibungssprache wird √§hnlich zu bereits bekannten Modellierungsprache wie die "Ereignisgesteuerte Prozesskette" (EPK) sein. EPK zeichnen sich dadruch aus, dass auf ein Ereignis immer eine Funktion (Prozess) folgt. 

Die Modellierung soll zwei Zwecken dienen: Zum einen sollen auf Basis der Konfiguratin m√∂gliche viele Apache-Kafka Artefakte generiert werden und zum anderen sollen die soll die Abfolge der Prozessschritte zur Laufzeit kontrolliert werden k√∂nnen um die Korrektheit eintreffender Ereignisse zu √ºberpr√ºfen. 
Hierbei ist eine grafische Modellierung, wie es bei EPK oder BPMN √ºblich ist nicht sinnvoll, deshalb wird eine Beschreibungspsrache in textform genutzt werden. Bei einer potentiellen sp√§teren Weiterenwicklung ist die Entwicklung einer grafischen Front-Ends denkbar.  

Im Rahmen dieses Prototypes stehen bei der Beschreibungssprache vor allem prakmatische Aspekte im Vordergrund und folgt daher einen simplen Aufbau. Allerdings soll die Notation so konzipiert sein, dass komplexere Elemente sp√§ter noch hinzugef√ºgt werden k√∂nnen. Denkbar sind hier unter anderem logischer Operatoren mit denen z. B. eine parallelisierte Darstellung von Gesch√§ftsprozessen m√∂glich w√§re.

Die DSL ist f√ºr nicht technische Nutzer gedacht welche bereits Kentnisse mit der Syntax von JSON besitztn. F√ºr eine vereinfachte Benutzung ist auch die Implementierung einer grafischen Benutzeroberfl√§che als Front-end, mit welcher die DSL erzeugt werden k√∂nnte. 

### Implementation Modul 1
##### JSON Schema
F√ºr die Syntax der Beschreibungssprache wurde die JavaScript Object Notation (JSON) gew√§hlt. Dies ist ein kompaktes, menschenlesbares Datenformat welches verbreitet in der Client-Server Kommunikation ist. 

JSON besitzt standardm√§√üig nur wenige Syntax- und Strukturregeln. Deshalb es von N√∂te zus√§tzliche Regeln f√ºr den Aufbau des JSON festzulegen. 
Deshalb wurde sich entschiedenen ein JSON-Schema, welches einen festgeschriebenen Standard f√ºr den Aufbau des JSON Doluments darstellt, zu nutzen. 
Die Nutzung eines JSON-Schemas wurde gew√§hlt, da die Confluent-Platform mit der *Confluent Schema Registry* ein RESTful interface bereitstellt (mehr in Modul2). 

Dies erm√∂glicht die Verarbeitung der Notation druch weitere Programme sowie die Validierung der Syntax. 

Als beispielhafter prozess k√∂nnter folgender verwendet werden:

![Process](process.jpg "Beispielprozess")

Um ein das Architekturprinzup "Seperation of Concerns" zu gew√§hrleisten wird das schema in zwei Teile aufgeteilt:
- **configschema:** Gibt nur den Namen der events sowie die Namen der Eigenschaften jedes Events.
- **dataschema:** H√§lt die Daten von Events welche am Anfang der Laufzeit erstellt werden sollen. Sp√§ter k√∂nnen nat√ºrlich weitere Events erstellt werden. 

Diese ist auch aus technischer Sicht notwendig, da die Erstellung der Ereignisse und die √úberf√ºhrung der Daten in Objekte in zwei unterschiedlichen Schritten stattfinden. Da das configschema sowohl ds JSON-Schema standard als auch den Eigenschaften des Avro-Schemas ensprechen muss w√ºrde eine Zusammenlegung der Schemas in einen hohen Aufwand m√ºnden. 

##### JSONSchema
![JSONSchema](json_schema.png "JSONSchema")
![DataSchema](data_schema.png "DataSchema")
 
#### JSON zu Avro Schema 
Mit der Beschreibungssprache lassen sich noch keine Kafka Komponenten generieren. Hierf√ºr muss ein weiteres Datenschema erzeugt werden, welches in Kafka Architekturen genutzt wird. In Kafka wird hierf√ºr in der Regel die Confluent Schema Registry genutzt. Dise stell ein RESTful Interface f√ºr das speichern abrufen sogenannter *Avro JSONSchemas* zur verf√ºgung. 

Die zentrale Funktion der Confulent Schema Registry ist die *Schema-Evolution*. Sollte ein bereits vorhandenes Schmema ver√§ndert werden bietet Condluent eine automatische Versionierung an. Damit wird eine Anpassbarkeit des zugrundeleigenden Speichermechanismus von Apache Kafka erm√∂glicht.

Im Prototyp ist es damit m√∂glich Porzess√§nderungen w√§hrend der Laufzeit vorzunehmen. Sollte also neue Prozessschritte hinzukommen, wegfallen oder sich √§ndern, kann die DSL ge√§ndert werden ohne das die bisherige Architektur komplett neu erstellt werden muss. Ohne die Nutzung die Schema-Evolution m√ºsse bei jeder √Ñnderung am Schema die Architektur neugestartet werden. 

Um aus der bisherigen Beschreibungssprache ein *Avro JSON Schema* zu serialisieren wird die Scala Bibiliothek *avro4s*  verwendet. Das enstprechende Modul erh√§lt als Input das JSON-Schema transformiert dieses in ein Avro-Schema. 

## Modul 2: Generator 
- Parse Data Schema -> Avro Objects from Avro Classes (Event, Prop) -> Producing

Ziel dieses Moduls ist die Implementierung Generators, welcher anhand der zuvor beschriebenen Beschreibungssprache als Input ensprechende Apache Kafka Komponenten erzeugt. Hierzu geh√∂ren Producer, Consumer, Topics sowie die definierten Ereignisse und deren Eigenschaften. 

Hierbei wird wieder keine grafische Benutzeroberfl√§che implementiert, das Programm ist ausschlie√ülich √ºber das Terminal oder die entsprechenen Entwicklerwerkzeuge steuerbar. 

### Implementation Modul 2
Die Producer und Konsumer in Kafka sind in Java geschrieben. Um das Avro Schema nutzbar zu machen muss dieses erst Sinnvoll in Java-Klassen umgewandelt werden. Avro hat die F√§higkeit Java Code aus einem Avro Schema zu erstellen. Mithilfe des Build Management Tools Apache Maven ist die sehr einfach in jeder IDE m√∂glich. 

Im oben aufge√ºhrten Beispiel werden die Java Klassen "Event" und "Propertie" erstellt. Welche entsprechend Events und deren Eigenschaften repr√§sentieren. 

Eine Herausforderung hierbei ist, dass die generierten Klassen sich je nach Prozess deutlich unterscheiden. Die Anzale der Ereignisse sowie die Anzahl und Datentypen deren Eigenschaften √§ndern sich mit jeder neuen Prozessbeschreibung. Beispielsweise k√∂nnte das Ereignis "Auftragseingang" die Eigenschaften Auftragsnummer, Name und Datum haben, w√§hrend das Eregnis "Rechnung beglichen" die Eigenschaften zus√§tlich die Eigenschaften "Rechnungsnummer und "Betrag" halten k√∂nnte.
Diese variablilt√§t der "Event" sowie "Propertie" Klassen macht die Verarbeitung dieser mit einem statischen Java-Programm unm√∂glich. 

Deshalb wird hier das Prammierprinzip Introspektion (engl. reflection) verwendet. Dieses bedeutet dass das Progbramm zur Laufzeit seine eigene Struktur kennt und modifizieren kann. In diesem Fall passt sich der Programmcode die √úberf√ºhrung der Daten in die Java-Objekte an die generieren Klassen zur Laufzeit an. Dies hat den Vorteil das der Programmcode nicht manuell angepasst werden muss und dier somit flexibel auf sich ver√§rnde Klassenstrukturen reagieren kann.  
Um dies Umzusetzen gibt es die Klassen *"Reflection"* und *"AvroAutoCoder"* welche die Funktion √ºbernehmen. 

Anschlie√üend √ºbernimmt der *JsonObjectMapper* das Mapping der Daten im Datenschema auf Java-Objekte indem das Datenschema geparsed wird. Diese Objekte werden im folgenden *Avro-Objekte* genannt. 
Mit den generierten Avro-Objekten kann ein Avro-Kafka-Producer umgehen und diese in die entsprechenden Topics produzieren. Hierf√ºr werden zur Laufzeit f√ºr jedes Ereigniss  drei Topics erstellt. Zum einen wird inbound-Topic erstellt, in welchem alle bisher noch nicht validierten Ereignisse gespeichert werden. Zum anderen werden f√ºr des Ereignis ein outbound- sowie error-Topic erstellt in welchem sp√§ter korrekt oder inkorrekt validierte Ereignisinstanzen gespeichert werden. 

Die Erstellung der Topics √ºbernimmt der *TopicHandler*, die namen der topics werden der Konfiguration entnommen. Die Namen der Topics werden aus der Konfiguration entnommen und jeweils durch ein "-in", "-out", "-err" weitert. Damit ist es weiteren Komponenten, wie dem Validator, m√∂glich diese Topics nur mit der Kenntnis der Konfiguration zu verwenden. 

## Modul 3: Validator
Im Validator steckt die Kernfunktionalit√§t der Architektur. Ziel des Validators ist zur Laufzeit alle eintreffenden Ereignisse nach festgelegten Kriterien zu validieren. Dies k√∂nnte z.B. sein dass ein Ereginiss einer Prozessinstanz zugeordnet werden kann oder das die Properties eines Ereginisses bestimmtem Kriteren entsprechen. Abh√§ngig von dem Ausgang der Validation werden die Ereginisse welche sich anfang in einem der Inobound-Topics befinden in eines der beiden anderen Topics gespeichert werden.

Zur Laufzeit k√∂nnen somit fehlerhafte Ereignisse "herausgefiltert" werden. Damit wird die weitere Verarbeitung von Fehlerhaften Ereignissen verhindert. 

Durch den Validator erreicht die Architektur eine Struktur welche mit der Mediator Topologie vergleichbar ist. Der entscheidente Vorteil dieses Architekturansatzes ist, dass Fehler welche zur Laufzeit direkt erkannt und somit nicht wiederholt werden k√∂nnen. Bei der Anwendung von Publish-Subscribe Systemen im Unternehmenskontext werden nicht selten Millionen von Ereignissen in der Sekunde verarbeitet. Einfache Fehler k√∂nnen sich somit in kurzer Zeit oft wiederholen. Durch diese Architekturprinzup werden Ereignisse zur Laufzeit gepr√ºft und validiert und die wiederholdung von Fehler nwird somit ausgeschlossen  

### Implementation
Ein Kafka-Avro-Consumer abboniert alle zuvor erstellen Topics und empf√§ngt alle Ereignisse aus. Anschlie√üend werden die Ereignisse einer logischen Pr√ºfung unterzogen und abh√§nging vom Ausgang der tests in das outbound- oder error-Topic gespeichert. 
Momentan werden im Prototyp die Konfiguraton als auch die Logik der Prozessintanzen √ºberpr√ºft. Die Konfiguration wird bereits w√§hrend des Setups des Prototypes gepr√ºft. Sollte sich ein Fehler im JSON-Schema oder Datenschema befinden wird eine Entsprechende Ausnahme geworfen. Die Prozessinstanzen werden w√§hrend der Laufzeit f√ºr jedes konsumierte Event gepr√ºft. Jedes Event erh√§lt in der Konfiguraton eine eindeutige ID welche die Position im Prozess festlegt. 

Zur Laufzeit verfoglt der Validator alle eintreffenden Ereignisse und versucht diese einer bestehenden Prozessinstanz zuzuordnen. Sollte es sich um ein Ereignis mit der id 1 handeln wird eine neue Prozessinstanz erstellt. Alle bisher erstellen Prozessinsanzen werden in einer Mapping-Tabelle den IDs der Ereignisse zugeordnet. Somit ist es dem Validator m√∂glich eintreffende Ereignisse zu √ºberpr√ºfen.  

# 4 Demonstation
## Konfiguration
Zuerst muss das Artefakt konfiguriert werden. Dies involiert das JSONSchema als auch das Datenschema. Die Ereignisse (Events) des ereignisgesteuerten Prozesses sowie die Attribute (Properties) werden definiert. Im Datenschema k√∂nnen Daten f√ºr jedes definierte Event festgelegt werden. 

*Screenshots Schemas*

## Laufzeit
Um die Ereginisse f√ºr Kafka nutzbar zu machen m√ºssen diese in meheren Schritten in Java-Objekte √ºberf√ºhrt werden. Dies geschieht wie zuvor beschrieben mittels einer Serialisierung des JSON-Schemas zu einem Avro-Schema und anschlie√üend werden aus diesem Schema Java-Klassen mittels Maven erstellt. Aus diesen Klassen werden zur Laufzeit Objekte generiert welche mit den Daten des Datenschemas bef√ºllt werden. 

F√ºr jedes Ereginis werden die entsprechenden Topics vom *TopicHandler* erstellt. 

*ScreenShot Topics*

Alle eingehenden Ereignisse werden von einem Kafka-Producer in die entsprechenen Inbound-Topics produziert. Die Ereignisse welche im Datenschema w√§hrend der Konfiguration festgelegt wruden werden als erstres produziert. 

Jedes eingehende Ereignis wird nachdem es in ein Inbound-Topic produziert wude vom Validator konsumiert und validiert. Sollte die Validierung positiv ausfallen wird das Ereigniss in das entspechende Outbound-Topic gespeichert, ansonsten wird es ein ein Error-Topic gespeichert. 


## Verarbeitung eines Fehlers w√§hrend des Konfiguration
Sollte sich nicht an die korrekte Syntax des JSON-Schemas gehalten werden m√ºssen ebenfalls Fehler erzeugt werden. 
Durch die Nutzung von JSON-Schema und deren Libraries bereits eine vollst√§ndige Valdierug des Schemas gegeben. Der Serialisierung des Avro-Schemas wird eine Validierung zugef√ºhrt und eines ensprechende Ausnahme geworden sollte sich ein Fehler im Schema befinden. 


## Verarbeitung eines Fehlers zur Laufzeit
W√§hrend der Laufzeit ist es nat√ºrlich m√∂glich weitere Ereignisses zu erzeugen. Im folgenden wird demonstriert was bei der w√§hrend der Validierung eines Fehlerhaften Ereignisses passiert. 

Im folgenden wird mittels eines weiteren Producers ein Ereignis erzeugt, welches keiner bestehenden Prozessinstanz zugeordnet werden kann und somit als fehlerhaft gewertet wird. 

# 5 Evaluation
## √úbersicht
![Evaluationstabelle](evluation_table.png "Evaluationstabelle")

In der folgenden Evaluation wird die Architektur anhand Ihrer Module sowie deren Bestandteile gemessen. Da es sich hierbei um gr√∂√ütenteils generische Begriffe handelt bedarf es einer Definition im Kontext des Artefakts.
Die Anwendungs als ganzes wird *Artefakt* genannt. Das Artefakt besteht aus drei *Modulen* Notation, Generator und Validor. Jedes dieser Module besteht widerum aus *Komponenten* welcher wiederum aus *Objekten* im Programmierkontext bestehen.  
Als Komponenten werden hier einzelne Klassen oder Klassen welche eine Funktionalit√§t erf√ºllen abgegrenzt. 

*√úbersicht der Komponenten und Module*

![Klassendiagramm](class_diagram.png "UML-Klassendiagramm")
![Komponenten](4Archive/%F0%9F%8E%93%20Bachelorarbeit/Bachelorarbeit/4/componentsd.png "√úbersicht der Komponenten."){width=80%}

## Tauglichkeit
Um die Tauglichkeit des Artefakts zu bestimmen muss √ºberpr√ºft werden, ob das Artefakt die funktionalen Anforderungen erf√ºllt und ob die Umsetzung des Anfoderungen angemessen ist. 

Die Metriken sind hierbei:
1. **Vorhandenheit:** √úberpr√ºfung jeder funktionalen Anforderungen: Ist diese vorhanden? 
2. **Angemessenheit:** Entspricht die Umsetzung der Spezifikation oder besteht hier noch nachbesserungsbedarf? 

Im folgenden werden alle Anfoderungen an das Artefakt einzeln evaluiert. Hierbei wird auf die Angemessenheit der Umsetzung sowie Verbesserungsm√∂glichkeiten eingengangen. 
	
##### A1 Beschreibungssprache:
Der Anwender kann zur Setup-Phase ereignisgesteuerte Gesch√§ftsprozesse anhand einer Beschreibungsprache im JSON-Schema Format modellieren sowie initiale Daten in einem weiteren Schema (Datenschema) mitgeben. 

Es sind einfache, lineare Prozesse mit einer begrenzten typisierung m√∂glich. Durch die Nutzung von JSON Schema sowie eine offene implementierung ist eine erweiterung des Schemas f√ºr komplexere Gesch√§ftsprozesse m√∂glich. 
Denkbar ist die implementierung weiterer Datentypen oder die Einf√ºhrung von logischen Elementen mittels Operatirn wie "OR" oder "AND". Diese Logik muss alerdings auch im Rest der Anwendungs realisiert werden. 

##### A2  Syntaxpr√ºfung: 
Wenn der Anwender mit einem Fehler die Syntaxregeln von JSON-Schema verletzt wird bei der Umwandlung des Schemas in ein Avro-Schema eine Ausnahme geworfen. Diese Ausnahmen stammen von der *avro4s* Bibliothek und werden nicht ver√§ndert. 
F√ºr einen nicht-technischen Nutzer sind diese Ausnahmen schwer lesbar, f√ºr die Benutzbarkeit m√ºssen hieraus noch lesbare Fehler generiert werden. Dies k√∂nnte mit einem passenden Front-End, wie einem grafischen Editor, erreicht werden. 

Fachliche Fehler im Prozess werden weder in der Setup-Phase noch zur Laufzeit √ºberpr√ºft. 

##### A3 Erstellung von Kafka Komponenten:
Zur Laufzeit erstelle das Artefakt alle spezifizierten Komponenten. Im Umfang der Protoyps wird zur Laufzeit ein Producer sowie ein Consumer erstellt. F√ºr jedes Ereignis werden drei Topics vom *Topic Handler* erstellt. 
Die Anzahl der Ereignisse und Topics ist damit anhand der Konfiguration variierbar. Weitere Producer und Consumer k√∂nnten Problemlos hinzugef√ºgt werden. 

Somit die die Anfoderung A3 erf√ºllt.

##### A4 Validierung: 
Zur Laufzeit ist das Artefakt in der Lage eintreffende Ereignisse zu validieren. Momentan findet eine logische Validierung zur Sicherstellung der Konsistenz einzelner Prozessinstanzen statt. Wenn in der Konfiguration eine Verkettung aus "Ereignis_A" und "Ereignis_B" vorsieht zur Laufzeit aber ein "Ereignis_B" eintritt ohne dass im Zeitraum zuvor das andere Ereignis verarbeitet wurde wird ein Laufzeitfehler erzeugt. 

Eine erweiterde Validierung ist ebenfall denkbar. Beispielsweise k√∂nnten die Werter innerhalb der Prozesse gepr√ºft werden oder "leere" Ereignisse gefiltert werden. Der Protoyp k√∂nnte ohne weiteres mit diesen Validierungen erweitert werden. 

Die Anfoderungen A4 ist erf√ºllt. 

##### A5 √Ñnderungen zur Laufzeit
Bei einer √Ñnderung der Konfiguration gibt es im Prototyp gibt es im Prozess eine Stelle welche einen manuellen Eingriff ben√∂tigen. Das JSON-Schema muss mit mittels eines weiteren Projekts in ein Avro-Schema umgewandelt. Aus diesem Avro-Schema m√ºssen ebenfalls manuell mit Maven die Avro-Klassen generiert werden. Dieser Schritt w√§re mit zus√§tzlichem Entwicklungsaufwand auch automatisierbar.

Die restlichen Module des Artefakts wurden so konzipiert, dass Sie Ver√§nderungen der Konfiguration automatisch umsetzen k√∂nnen. Insbesondere der Code des Generators muss sich an die Ver√§nderungen der Avro-Klassen anpassen. Damit der Code nicht manuell angepasst werden muss wird hier Reflection genutzt um einen den relevanten Teils des Codes zur Laufzeit automatisch zu generieren (vgl. Konzeption und Entwicklung)

### Zusammenfassung
Damit sind folgende Anforderungen erf√ºllt: 

|Anfoderung    |Vorhandenheit|Angemessenheit
|---    	    |:---:|:---:|
|A1 Beschreibungssprache             | x |   
|A2 Syntaxpr√ºfung                    | x |   
|A3 Erstellung von Kafka Komponenten | x |   
|A4 Validierung                      | x |   
|A5 √Ñnderungen zur Laufzeit          |   |   

Damit sind 80% der Anfoderungen erf√ºllt und die Architektur erf√ºllt damit das Design Principle "Tauglichkeit".

## Fehlertoleranz 
Um fehlertolerant zu sein, muss √ºberpr√ºft werden, ob das Artefakt auch in der Lage ist ein definiertes Leven an Performanz zu halten auch wenn Fehler oder Verst√∂√üe gegen Regen vorleigen.

Metriken sind hierbei:
1. **Fehlerbehandlung:** Evaluation ob Mechanismen oder Softwarebestandteile vorhanden sind, welche Fehler verarbeiten k√∂nnen. Beispiele hierf√ºr ist die Behandlung von Ausnahmen (*Exceptions*) oder das Verhindern von Redundanzen.

Wenn sich ein Fehler in der Konfiguration, dem Schema, des Artefakts befindet wird bei der Serialisierung des Avro-Schmeas eine Ausnahme geworfen. Mit einem Fehler in der Konfiguration w√§re die Architektur nicht lauff√§hig, deshalb muss der Fehler vom Nutzer behoben werden bevor das Programm weiter ausgef√ºhrt werden kann. 

Der Fehler wird momentan in einer Ausnahme (Exception) ausgegeben wie es im Softwareentwicklungsumfeld √ºblich ist. F√ºr einen nicht-technischen Nutzer wersind  diese allerdings nur schwer verst√§ndlich sein. F√ºr eine h√∂here Usability m√ºssen hier verst√§ndlichere Fehler erzeugt werden. 

Treten fehlerhafte Ereignisse zu Laufzeit auf, meist fehler hafte Prozessinstanzen, wird dies vom Validiator erkannt und in entsprechende Error-Topics gespeichert. 
Treten w√§hrend der Laufzeit fehlerhafte Ereignisse auf, wird die vom Validator erkannt und diese werden im entsprechenden Error-Topic gespeichert. Damit wird der ensprechende Prozess mit einem Laufzeitfehler aufgehalten bis eine Kl√§rung des Fehlers erfolgt. 
Fehlerhafte Ereignisse beinflussen somit nicht die Performanz des Systems.  

## Interoperabilit√§t 
Damit das Design Principle erf√ºllt ist m√ºssen die Module und Komponenten des Artefekts gelcihe Strukturmerkmaleverwenden. Des Weiteren muss das System in der Lage sein mit anderen Systemem zu inteagieren. Im Ideafall wird dies durch die Verwendung von g√§ngigen Standards erreicht. 

Um das Artefakt auf das Design Principle "Interoperabilit√§t" erreich muss das Ziel der "hohen Homogenit√§t" erf√ºllt werden. Dieses erfordert einheitliche systeme und Schnittstelle und setzt sich damit aus den Zielen "Einheitliche Technologie" und "Einheitliche Schnittstellen" zusammen. 

![zh_interoperablilit√§t](zh_interoperabilit%C3%A4t.png "Zielhiearchie: Interoperabilit√§t")

Aus der Zielhiearchie werden folgende Metriken abgeleitet: 

### Standardisierung der Anwendungskomponenten 
*Anwendungskomponenten m√ºssen die gleichen Strukurmerkmale verwenden als auch so gut es geht die gleichen technoligien nutzen.*

Das Artefakt benutzt haupts√§chlich Technologien um Umfeld der Conflunt Platform und damit Apache. Hierzu geh√∂rten Apache Kafka und alle seine Komponenten, die Schema Registry. Das Software Development Kit (SDK) von Apache Kafka ist in Java implementiert. 
Die Schema Registry basiert auf JSONSchema. Somit basieren alle Komopnenten, au√üer der *JsonToAvroConverter* auf diesen Technologien. Dieser nutzt die Bibliothek *avro4s*, welche nicht Teil der Confluent-Platform ist und welche Scala anstatt Java nutzt. 

Somit ist das Kriterium weitgehend erf√ºllt. F√ºr eine vollst√§ndige Erf√ºllung m√ºsste die Funktionalit√§t der *avro4s*-Bibliothek vollst√§ndig in Java implementiert werden. Eine Java-Bibliothek existiert hierf√ºr nicht. 

- **Schnittstellenstandardisierung:** Der Informationsaustausch zwischen Komponenten, Modulen und kompletten Anwendungssystemen muss √ºber standardisierte Schnittstellen stattfinden. 

Das Artefakt enh√§lt keine anwendungs√ºbergreifende Schnittstellen. Somit werden nur die Schnittstellen zwischen den Modulen betrachtet.  

Zwischen dem Modulen "Notation" und "Generator" wird √ºber Daten im JSON-Schema Format kommuniziert. Das Datenformat selbst standardisiert (RFC 8259) und weit verbreitet. Die Umwandlung von einem *AvroSchema* zu *Java Klassen* ist aber ein Feature spezifisch f√ºr das Build-Mangement-Tool "Apache Maven". Somit entspricht die Schnittstelle keinem Standard sondern befindet sich im im Bereich der Apache-Technologien.

Die Schnittstelle zwischen den Modulen "Validator" und "Generator" ist durch die Nutzung von Apache Kafka standardisiert. Jeder Producer und Consumer, welcher sich an die spezifizierten Richtlinen von Kafka h√§lt kann in der Anwendung mitwirken. 

### Konnektoren 
*Idenfifikation von Konnektoren welche mit externen System kommunizieren k√∂nnten.*

Die Integration weiterer Systeme ist √ºber Apache Kafka m√∂glich. Weitere Consumer k√∂nnten Ereignisse der Anwendungs weiter verarbeiten.

## Modifizierbarkeit
*Wie ist die Komplexit√§t der Module und damit des  gesamten Systems einzusch√§tzen?*

![zh_modigizierbarkeit](zh_modifizierbarkeit.jpeg "Zielhiarchie Modifizierbarkeit")

**Fragen** 
- Kann das Artefakt einfach ver√§ndert und modifiziert werden, um zum Beispiel neue Funktionalit√§ten zu implementen?

### (Geringe Vernetzung)
Das erste Modul, die Notation, ist simple gehalten. Durch die Aufteilung in zwei Schemas ist die Komplexit√§t eines einzelnen Schemas √ºberschaubar. Was die Komplextit√§t im ersten Modul deutlich erh√∂ht ist die Implementierung des *JsonToAvroConverter* in einer weiteren Programmiersprache (Skala). 

Das Zweie Modul, der Generator ist von der grundlegenden Struktur ebenfalls simpel gehalten. Da hier durch den *AvroAutoCoder* zentrale Code-Bestandteil zur Laufzeit generiert werden entsteht hier auch Komplextit√§t. Die genierten Code-Benstandteile unterscheiden sich bei jeder Ausf√ºhrung, bei der auch das JSON-Schema ver√§ndert wird. Des Weiteren wird dadurch das Debuggung f√ºr den Entwickler erschwert. 

Komponenten wie der *TopicHandler* oder der *JsonObjectMapper* unterscheiden sich in ihere Komplextit√§t nicht sonderlich von vergleichbaren implementationen. Der *JsonObjectMapper* nutzt hierbei g√§ngige Bibliotheken f√ºr das verarbeiten von JSON Dokumenten. 

Alle Kafka Komponenten unterscheiden sich kaum von der Standarimplementation. Hier wurde nicht viel hinzugef√ºgt. Da die Kafka-SDK auf einem hohen Abstaktionslevel ansetzt ist auch hier die Komplexit√§t √ºberschaubar. 

Insgesamt ergibt sich eine Mischung aus komplexen und unkomplexten Komponente. Deshalb ist das Design Principle nur teilweise erf√ºllt. 

### Hohe Homogenit√§t
Das Design Principle "Modifizierbarkeit" teilt sich mit "Interoperabilit√§t" das Unterzhiel "Hohe Homogenit√§t". Einheitliche Systeme und Schnittstellen tragen ebenfalls dazu bei, dass das Artefakt leichter modifiziert werden kann. 

Die Ziele welche die Homogenieit√§t des Artefakts wurden bereits evaluiert. Insgesamt ist das Artefakt homogen genug, so dass jede Komponente ohne gro√üen Aufwand modifiziertbar ist. Hierauf wirkt sich auch positiv aus, dass der Umfang des Artefakts im Vergleich zu einer produktiven Anwenungs begrenzt ist. 

### Datenredundanzfreiheit
Innerhalb des Artefakts kann zwischen drei Datenbest√§nden unterschieden werden, welche an unterschiedlcihen Stellen verwaltet werden. 
Den ersten Datenbestand stellen die vom Nutzer erstellen Schemas (JSON-Schema, Datenschema) dar. Diese Schema werden im Modul "Notation" erstell und im Modul "Generator" verwaltet und verarbeitet. Hierbei entstehen keine Redundanzen. 
Die aus den Schemas erstellen Ereignis-Objekte k√∂nnen als eigener Datenbstand betrachtet werden. Diese Daten werden ausschlie√ülich im Modul "Generator" vewaltet und verarbeitet, hier bestehen auch keine Redundanzen. 
Der Drite Datenbestand sind die Kafka-Ereginisse. Im Artefakt werden diese von einem Broker verwaltet, somit bestehen hier ebenfalls keine Redundanzen. Allerdings k√∂nnten bei einer sp√§teren erweiterung des Artefakts durch weitere Producer, Consumer und Broker Datenredundanzen entstehen, dies sollte vermieden werden. 

Eine Datenredundanzfreiheit ist gew√§hrleistet. 

## Austauschbarkeit
**Fragen(n)**
- Sind die Komponenten des Artefakts entkoppelt und damit austauschbar? 
![[zh_austauschbarkeit.png]]

### Hohe technische Modularit√§t
F√ºr eine hohe technische Modularit√§t ist eine Entkopplung der Module Notwendung. Die Module sind weitestgehend entkoppelt. Das Modul Notation kommuniziert mit dem Generator Modul nur √ºber die definierten Schemas. Daher ist die einzige Abh√§ngigkeit hier die Strukturmerkmale der Schemas, diese Abh√§ngigkeit liegt der Funktionsweise des Artefakts zugrunde und ist nicht verhinderbar. Sollten sich die Strukturmerkmale oder die Anzahl der Schemas ver√§ndern m√ºsste die Komponente JsonObjectMapper entsprechend angepasst werden. Sollten die Ver√§nderungen so weitreichend sein, dass die Regeln von JsonSchema nicht mehr eingehalten werden, m√ºsste die JsonToAvro-Komponente ebenfalls angepasst werden.

Das Modul Generator kommuniziert mit dem Validator-Modul ausschlie√ülich √ºber Kafka-Komponenten. Mit einen Producer werden Events produziert und √ºber einen Broker mit einem Consumer empfangen. Die Implementierung weicht hierbei nicht vom Standard in Apache Kafka ab. Publish-Subscribe-Architekturen wie Apache Kafka zeichnen sich durch eine Entkopplung der einzelnen Komponenten aus. Damit sind die einzelnen Kafka-Komponenten Events, Topics, Producer und Consumer komplett entkoppelt. Die einzelnen Kafka Komponenten k√∂nnen jederzeit und ausgetauscht werden.

Somit ist der Kopplungsgrad zwischen den Modulen Notation und Generator mittel. Der Kopplungsgrad zwischen den Modulen Generator und Validator ist gering.

Des weiteren ist bei einer hohen technischen Modularit√§t notwendig, dass die Anwendung nach technischen Kriterien strukturiert wird (vgl. theoretische Grundlagen). Nach Engels et al. (2008) handelt es sich bei dem Modul ‚ÄúNotation‚Äù um eine Interaktionskomponente, welche der Interaktion mit Anwenden dient. Allerdings k√∂nnte es auch teilweise als Funktionskomponente bezeichnet werden da im JsonToAvroConverter Funktionalit√§t implementiert ist. Hier besteht also eine unscharfe Definition.

Bei dem Modulen ‚ÄúGenerator‚Äù handelt es sich um eine Prozesskomponente, welche der Abbildung und Steuerung fachlicher Gesch√§ftsprozesse dient. Das Modul ‚ÄúGenerator‚Äù ist eine Funktionskomponente, welche eine Funktionalit√§t (die Validation) implementiert.

Somit l√§sst ist eine technische Modularit√§t der Komponenten feststellbar, auch wenn diese teilweise unscharf bei einzelnen Komponenten existiert.

### Austauschbarkeit der Komponenten 
*Identifizierung und Z√§hlung der Austauschbaren Komponenten.*

Im folgenden wird anhand einer Auflistung aller Komponenten des Artefakts bestimmt, welche der Komponenten austauschbar ist. Als Austauschbar gilt hierbei eine Komponenten, deren Austausch durch eine andere oder ver√§nderte Komponenten die restliche Architektur nicht beinflussen w√ºrde. 

| Komponente | Austauschbar? | Beinflusse Komponenten |
|:-----------|:--------------|------------------------|
|JsonSchema + JsonToAvroConverter | Nein | JsonObjectMapper
|MavenClassGenerator | Ja | - 
|Event + Propertie| Ja | -
|Propertie | Ja | - 
|AutoCoder | Ja | - 
|DataSchema | Nein | JsonObjectMapper
|JsonObjectMapper | Nein | JsonSchema, DataSchema |  
|AvroProducer | Ja | - | 
|TopicHandler | Ja | - | 
|AvroConsumer | Ja | - | 
|Validator | Ja | - | 

Die Komponenten *JsonSchema*, *DateSchema* und *JsonObjectMapper* besitzen eine hohe Kopplung zueinander. Da der JsonObjectMapper die beiden Schemas verarbeitet m√ºsste er bei einer Ver√§nderung dieser ebenfalls angepasst werden. 

Damit sind 70% aller Komponenten austauschbar. Somit ist das Design Principle erf√ºllt. 

Durch eine modulare Struktur und die Vermeidung von Redudanzen innerhalb der Anwenudngslandschaft k√∂nnen bestehende Daten und Funktionen wieder verwendetet werden. Dies f√ºhrt zu einer hohen funktionalen Agilit√§t.
Wie bereits festgestellt ist die Autauschbarkeit und damit die Modularit√§t des Artefakts gegeben. Des weiteren zeichnet befinden sich im Artefakt auch wenige Redundanzen. 

### Funktionale Redundanzfreiheit
Im Artefakt befinden sich keine funktionale Redundanzen. Dies ist vor allem dem Umfang des Artefakts geschulet. Alle implementierten Funktionen in der Regel nur an einer Stelle genutzt und nicht wieder verwendet. Bei einer erweiterung des Systems gilt es darauf zu achten vorhandene Methoden weiderzuverwenden anstatt die funktionalit√§t erneut zu implementieren. 

Eine funktionale Redundanzgreiheit ist gew√§hrleistet. 

### Ad√§quate Kopplung
Eine maximale Abh√§ngigkeit leigt vor, wenn Komponenten paarweise miteinander verbunden sind. Eine minimale Abh√§nigkgiet liegt vor, wenn keine Verbindungen exisiteren.
Um das Ziel der "Geringen Abh√§ngigkeit" zu erreichenm muss das Systeme eine geringe Vernetzung aufweisen und die vernetzten Systeme m√ºssen adequat gekoppelt sein (vgl. theoreische Grundlagen). 

Das Artefakt ist fachlich in drei Module "Notation", "Generator" und "Validator" gegliedert. Eine ad√§quate Kopplung erfodert, dass die Module unterneinter m√∂gliche wenig vernetzt sind (lose Kopplung), w√§hrend sie intern stark wenere sind (hohe Koh√§sion).

Das Modul "Notation" ist mit dem Modul "Generator" vernetzt durch die Komponenten "JsonToAvroConverter" und "MavenClassGenerator" (vgl. Komponenten√ºbersicht). Das Modul "Generator" und das Modul "Validator" sind ein Mal durch das Producer, Broker, Consumer Konstrukt von Kafka vernetzt. 

Die Komponenten innheralb der Module gekoppelt, was durch die Verbindungen in dder Modul√ºbersicht sowie das UML-Klassendiagramm dargestellt wird.

Die Komponenten sind Modulintern eng gekoppelt, w√§hrend die einzelnen Module durch zwei Schnittstellen lose gekoppelt sind. 

## Anpassbarkeit 
**Fragen**
- Ist das **Artefakt** in der Lage kapazitative und funktionale Ver√§nderungen der Umwelt schnell umzusetzen? 

### Adaptionsf√§higkeit der Komponenten
*Evaluiaton des Artefakts und seinen Komponente auf die F√§higkeit sich anzupassen.*

Das Artefakt besitzt implementierte Funktionen, um sich an Ver√§nderungen anzupassen. Die Kernfunktionalit√§t des Artefakt ist es, es sich an ver√§ndertet Konfiguartionon, oder fachlich augedr√ºck sich ver√§ndernde ereignischgesteuerere Prozesse anzupassen. Somit wurde diese Dynamik bei der Implementatoin beachet. 

Die Benutzten Werkzeugee und Bibliotheken besitzen bereits von Haus aus eine hohe Anpassbarkeit. Dies betriff die Schemas sowie den *JsonToAvroConverter*.
Dies Schemas werden vom User bearbeitet und sind daher schon bei normaler Benutzung einer st√§ndigen Ver√§nderung ausgesetzt. 
Der *JsonToAvroConverter* und dessen Bibliothek ist auch darauf ausgelegt sich st√§ndig ver√§rnde Schemas zu verarbeiten. 
Das Gleiche gilt f√ºr die generieren Avro-Klassen mittels Maven.  

F√ºr die Erstellung von Objekten aus Avro-Klassen wurde mittels dem Programmierprinzip Relektion die Komponente *AvroAutoCoder* erstellt welche zur Laufzeit angepasst Komponenten erstellt. Somit ist die Anwendungs in der Lage mit verschiedenen *Event* sowie *Propertie*-Klassen umzugehen. 

Kafka-Komponenten sind ebenfalls darauf ausgelegt angepasst zu werden. Diese ist sogar w√§hrend der Laufzeit m√∂glich ohne dass das System heruntergefahren werden muss. Inbesondere profitieren davon die Producer und Consumer. Um die Daten trotz Ver√§nderung konsistent zu speichern wurde die Confluent-Schema-Registy genutzt, deren zentrale Funktion die Schema-Evolution und damit die Anpassbarkeit des Kafka zugrundeliegenden Speichermechanismus erm√∂glicht.

### Skalierbarkeit
Publish-Subscribe-Architekturen sind theoretisch unbegrenzt vertikal skalierbar. Im Falle von Kafka k√∂nnen jederzeit neue Producer, Consumer sowie hinzugef√ºgt werden ohne dass die Perfomanz darunter leidet. 
Damit wei√üen die Kafka-Komponenten des Artefakt eine hohe Skalierbarkeit auf. 

Deshalb muss evaluiert werden inwiefern die Komponetnen, welche vor und nach Kafka geschaltet sind die Skalierbakeit beinflussen k√∂nnten. 
Das Modul "Generator" Artefakt, ist so implementiert, dass es momenten nur einen Kafka-Producer nutzt. Dies sch√§nkt die Skalierbarkeut deutlich ein. Das die Anzahl Ereignisse, welche gleichzeitig verarbeitet werden k√∂nnen begrenzt ist. Um weitere Producer zu nutzen m√ºssten alle Komponenten des Modules erneut seperator ausgef√ºhrt werden. 
Es w√§re aber m√∂glich einer Unterst√ºtzung von mehren Producern zu implementieren. 

Der Validator schr√§nkt die Skalierbarkeit nicht ein. Jedes Ereignis muss einen weiteren Schritt, die Validation, durchlaufen. Bei Bedarf k√∂nnen weitere Consumer mit angeh√§ngtem Validor genutzt werden. 


## Performance? 

